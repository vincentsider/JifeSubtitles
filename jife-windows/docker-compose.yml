# =============================================================================
# JIFE Subtitle System - Windows Docker Compose
# =============================================================================
# For Windows PCs with NVIDIA GPU (RTX 20xx/30xx/40xx).
#
# Usage:
#   Build:  docker compose build
#   Start:  docker compose up -d
#   Stop:   docker compose down
#   Logs:   docker logs subtitle-server -f
#
# Prerequisites:
#   - Docker Desktop with WSL2 backend
#   - NVIDIA Container Toolkit installed in WSL2
#
# Engine Options (WHISPER_BACKEND):
#   - faster_whisper: (DEFAULT) Option A - Whisper large-v3 direct translation
#   - seamless_m4t:   Option B - SeamlessM4T v2 speech-to-text translation
#   - pipeline:       Option C - Whisper transcribe + SeamlessM4T text translation
#
# To switch engines:
#   WHISPER_BACKEND=seamless_m4t docker compose up -d
#   WHISPER_BACKEND=pipeline docker compose up -d
# =============================================================================

services:
  subtitle-server:
    build:
      context: .
      dockerfile: Dockerfile

    image: jife-windows:latest
    container_name: subtitle-server

    working_dir: /app
    command: ["python3", "/app/app/main.py"]

    # NVIDIA GPU support for Windows/WSL2
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    restart: unless-stopped

    # Run as WSL user for PulseAudio access
    user: "1000:1000"

    # Environment variables
    environment:
      - PULSE_SERVER=unix:/mnt/wslg/PulseServer
      - AUDIO_DEVICE=${AUDIO_DEVICE:-0}
      - WHISPER_MODEL=${WHISPER_MODEL:-large-v3}
      - WHISPER_BACKEND=${WHISPER_BACKEND:-faster_whisper}
      - WHISPER_COMPUTE_TYPE=${WHISPER_COMPUTE_TYPE:-float16}
      - WHISPER_BEAM_SIZE=${WHISPER_BEAM_SIZE:-5}
      - WEB_PORT=5000
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - HF_HOME=/app/cache/huggingface
      - XDG_CACHE_HOME=/app/cache

    ports:
      - "5000:5000"

    volumes:
      - ./app:/app/app:ro
      - ./cache:/app/cache
      - /mnt/wslg:/mnt/wslg

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

volumes:
  whisper_cache:
    driver: local
